# Hyper-Resolution Image Super-Resolution Project

This project provides a unified framework for training, evaluating, and comparing deep learning models for single image super-resolution (SISR) using the DIV2K dataset. It supports classical architectures like SRCNN, VDSR, and RCAN, as well as custom variants like SvOcSRCNN and FusionNet.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ main.py                    # Entry point for training and evaluation
â”œâ”€â”€ config/config.yaml         # Configuration file (paths, hyperparameters)
â”œâ”€â”€ checkpoints/               # Saved model weights
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ data_loader.py         # Custom PyTorch Dataset & DataLoader
â”‚   â””â”€â”€ data_utils.py          # Image processing utilities
â”œâ”€â”€ Models/                    # Model architectures (SRCNN, VDSR, RCAN, etc.)
â”œâ”€â”€ Scripts/
â”‚   â”œâ”€â”€ train.py               # Unified training/validation/testing loop
â”‚   â”œâ”€â”€ train_srcnn.py        # Model-specific training (e.g., SRCNN)
â”‚   â”œâ”€â”€ train_rcan.py         # RCAN-style model training
â”‚   â”œâ”€â”€ visualize_results.py  # Result plotting & collage generation
â”‚   â””â”€â”€ utils/                 # Metric utilities (PSNR, SSIM), plotting, etc.
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/your-username/hyper-resolution.git
cd hyper-resolution
```

### 2. Set up environment
```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

pip install -r requirements.txt
```

Ensure you have an NVIDIA GPU and CUDA toolkit installed for best performance.

---

## ğŸ“¦ Dataset

This project uses the [DIV2K dataset](https://data.vision.ee.ethz.ch/cvl/DIV2K/).

Download the high-resolution images and place them in:

```
Data/DIV2K/
```

A preprocessing script will automatically resize and normalize images.

---

## âš™ï¸ Configuration

Edit `config/config.yaml` to set:
- Paths to training/validation/test data
- Model name
- Training parameters (epochs, batch size, loss)
- Device settings
- Optional logging

---

## ğŸ‹ï¸â€â™‚ï¸ Training & Evaluation

### Train a model
```bash
python main.py --model SRCNN
```

### Train RCAN-style model
```bash
python main.py --model RCAN --no_upsample
```

### Supported models
- `SRCNN`
- `SvOcSRCNN`
- `VDSR`
- `VDSR_SA`
- `RCAN`
- `FusionNet`

---

## ğŸ“Š Metrics

Evaluation uses:
- **PSNR (Peak Signal-to-Noise Ratio)**
- **SSIM (Structural Similarity Index)**
- **FID (FrÃ©chet Inception Distance)** *(if enabled)*

Results are logged to CSV and visualized using:
- Per-image annotated outputs
- Collages comparing multiple models

---

## ğŸ–¼ Example Outputs

<img src="results/collage_example.png" width="600">

---

## ğŸ›  Troubleshooting

- Ensure `torch` is GPU-enabled
- Clamp outputs with `.clamp(0, 1)` to avoid visual artifacts
- Validate model paths and image dimensions

---

## ğŸ“„ License

This project is for academic/research use only. For commercial use, please contact the author.

---